{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":99552,"databundleVersionId":13851420,"sourceType":"competition"},{"sourceId":13760622,"sourceType":"datasetVersion","datasetId":8756746}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# ==========================================\n# PHASE 2: 9-MODEL ENSEMBLE SUBMISSION SCRIPT\n# ==========================================\n# This script loads ALL model files, automatically finds\n# the 9 best (3 arch x 3 folds), and uses the\n# official rsna_inference_server for submission.\n\n# -------------------------\n# 1. GLOBAL IMPORTS\n# -------------------------\nimport os\nimport glob\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport functools\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport typing\nfrom typing import List, Tuple, Optional, Dict\nimport gc\nimport shutil\n\n# --- Competition-specific import ---\n# This block correctly handles both\n# \"Save Version\" (commit) and \"Submit\"\ntry:\n    import kaggle_evaluation.rsna_inference_server as rsna_inference_server\n    import polars as pl # Demo uses polars\n    print(\"Successfully imported rsna_inference_server.\")\nexcept ImportError:\n    # Create a minimal, empty MockEnv that does nothing.\n    import polars as pl # Still need polars\n    class MockEnv:\n        def __init__(self):\n            print(\"Creating simple MockEnv for 'Save Version' run.\")\n        def iter_test(self):\n            print(\"MockEnv.iter_test() called, returning empty list.\")\n            return [] # Return an empty iterator\n        def predict(self, submission_df):\n            print(\"MockEnv.predict() called. Skipping.\")\n    \n    rsna_inference_server = MockEnv()\n    print(\"Mock rsna_inference_server environment created.\")\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\n\nimport timm\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport pydicom\n\nwarnings.filterwarnings('ignore')\nprint(f\"Imports successful. PyTorch version: {torch.__version__}\")\n\n# -------------------------\n# 2. GLOBAL CONFIGURATION\n# -------------------------\nclass Config:\n    # -----------------------------------------------------------------\n    # --- !!! 1. EDIT THIS PATH !!! ---\n    # Change this to your dataset containing ALL 20+ model files\n    MODEL_DIR = \"/kaggle/input/newmodels\" \n    # -----------------------------------------------------------------\n\n    # --- Model Hyperparameters (MUST MATCH TRAINING) ---\n    NUM_FRAMES = 8\n    IMAGE_SIZE = 224\n    NUM_CLASSES = 14\n    NUM_FOLDS = 3 # Must match the number of folds you trained\n    \n    # --- Feature Flags (MUST MATCH TRAINING) ---\n    USE_METADATA = True\n    USE_WINDOWING = True\n    USE_CLAHE = True\n    \n    # --- Inference Config ---\n    TTA_ENABLED = True \n\n    # --- Define Models (MUST MATCH TRAINING) ---\n    MODELS_TO_TRAIN = [\n        (\"effnetv2s\", \"tf_efficientnetv2_s.in1k\"),\n        (\"convnext_tiny\", \"convnext_tiny.fb_in1k\"),\n        (\"maxvit_tiny\", \"maxvit_tiny_tf_224.in1k\"),\n    ]\n    MODELS_TO_TRAIN_DICT = dict(MODELS_TO_TRAIN)\n\nconfig = Config()\n\n# -------------------------\n# 3. GLOBAL SEED & DEVICE\n# -------------------------\ndef set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = False\n    torch.backends.cudnn.benchmark = True\nset_seed(42)\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# -------------------------\n# 4. GLOBAL TARGETS\n# -------------------------\nTARGET_COLS = [\n    'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery', \n    'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n    'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery',\n    'Anterior Communicating Artery', 'Left Anterior Cerebral Artery',\n    'Right Anterior Cerebral Artery', 'Left Posterior Communicating Artery',\n    'Right Posterior Communicating Artery', 'Basilar Tip',\n    'Other Posterior Circulation', 'Aneurysm Present'\n]\n\n# ----------------------------------------------------\n# 5. RE-USED HELPER FUNCTIONS (FROM TRAINING SCRIPT)\n# ----------------------------------------------------\ndef get_windowing_params(modality: str) -> Tuple[float, float]:\n    windows = {'CT': (40, 80), 'CTA': (50, 350), 'MRA': (600, 1200), 'MRI': (40, 80), 'MR': (40, 80)}\n    return windows.get(modality, (40, 80))\n\ndef apply_dicom_windowing(img: np.ndarray, window_center: float, window_width: float) -> np.ndarray:\n    img_min = window_center - window_width // 2\n    img_max = window_center + window_width // 2\n    img = np.clip(img, img_min, img_max)\n    img = (img - img_min) / (img_max - img_min + 1e-7)\n    return (img * 255).astype(np.uint8)\n\ndef apply_clahe_normalization(img: np.ndarray, modality: str) -> np.ndarray:\n    if not config.USE_CLAHE: return img.astype(np.uint8)\n    img = img.astype(np.uint8)\n    if modality in ['CTA', 'MRA']:\n        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n        img_clahe = clahe.apply(img)\n        img_clahe = cv2.convertScaleAbs(img_clahe, alpha=1.1, beta=5)\n    elif modality in ['MRI', 'MR']:\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        img_clahe = clahe.apply(img)\n        img_clahe = np.power(img_clahe / 255.0, 0.9) * 255\n        img_clahe = img_clahe.astype(np.uint8)\n    else:\n        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n        img_clahe = clahe.apply(img)\n    return img_clahe\n\ndef robust_normalization(volume: np.ndarray) -> np.ndarray:\n    if volume.size == 0:\n        return np.zeros((config.IMAGE_SIZE, config.IMAGE_SIZE), dtype=np.uint8)\n    p1, p99 = np.percentile(volume.flatten(), [1, 99])\n    volume_norm = np.clip(volume, p1, p99)\n    if p99 > p1:\n        volume_norm = (volume_norm - p1) / (p99 - p1 + 1e-7)\n    else:\n        volume_norm = np.zeros_like(volume_norm)\n    return (volume_norm * 255).astype(np.uint8)\n\ndef create_3channel_input_8frame(volume: np.ndarray) -> np.ndarray:\n    if len(volume) == 0:\n        return np.zeros((config.IMAGE_SIZE, config.IMAGE_SIZE, 3), dtype=np.uint8)\n    middle_slice = volume[len(volume) // 2]\n    mip = np.max(volume, axis=0)\n    std_proj = np.std(volume, axis=0).astype(np.float32)\n    if std_proj.max() > std_proj.min():\n        p1, p99 = np.percentile(std_proj, [5, 95])\n        std_proj = np.clip(std_proj, p1, p99)\n        std_proj = ((std_proj - p1) / (p99 - p1 + 1e-7) * 255).astype(np.uint8)\n    else:\n        std_proj = np.zeros_like(std_proj, dtype=np.uint8)\n    return np.stack([middle_slice, mip, std_proj], axis=-1)\n\ndef smart_8_frame_sampling(volume_paths: List[str]) -> List[str]:\n    n = len(volume_paths)\n    if n == 0: return []\n    if n <= 8:\n        result = volume_paths[:]\n        while len(result) < 8:\n            result.extend(volume_paths[:8-len(result)])\n        return result[:8]\n    start_idx = max(0, int(n * 0.1))\n    available_frames = n - start_idx\n    step = max(1, available_frames // 8)\n    indices = [start_idx + i * step for i in range(8)]\n    indices = [min(i, n - 1) for i in indices]\n    if len(set(indices)) < 8:\n        indices = np.linspace(start_idx, n-1, 8).astype(int).tolist()\n    return [volume_paths[i] for i in indices]\n\n# ---------------------------------\n# 6. MODEL DEFINITION (FROM TRAINING)\n# ---------------------------------\nclass ImprovedMultiFrameModel(nn.Module):\n    def __init__(self, model_name_backbone: str, num_frames=8, num_classes=14, pretrained=False):\n        super(ImprovedMultiFrameModel, self).__init__()\n        self.model_name_backbone = model_name_backbone\n        self.num_frames = num_frames\n        self.num_classes = num_classes\n        self.use_metadata = config.USE_METADATA\n        \n        self.backbone = timm.create_model(\n            self.model_name_backbone,\n            pretrained=pretrained,\n            num_classes=0,\n            global_pool='avg'\n        )\n        self.feature_dim = self.backbone.num_features\n        \n        if self.use_metadata:\n            self.meta_fc = nn.Sequential(\n                nn.Linear(2, 16), nn.ReLU(), nn.Dropout(0.2),\n                nn.Linear(16, 32), nn.ReLU()\n            )\n            classifier_input_dim = self.feature_dim + 32\n        else:\n            classifier_input_dim = self.feature_dim\n            \n        self.classifier = nn.Sequential(\n            nn.Linear(classifier_input_dim, 512),\n            nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.3),\n            nn.Linear(512, 256),\n            nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.3),\n            nn.Linear(256, num_classes)\n        )\n\n    def forward(self, x, meta=None):\n        features = self.backbone(x)\n        if self.use_metadata and meta is not None:\n            meta_features = self.meta_fc(meta)\n            features = torch.cat([features, meta_features], dim=1)\n        output = self.classifier(features)\n        return output\n\n# -------------------------\n# 7. INFERENCE: TRANSFORMS\n# -------------------------\ndef get_model_transforms() -> Dict[str, A.Compose]:\n    transforms = {}\n    \n    transforms[\"pytorch\"] = A.Compose([\n        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n        ToTensorV2()\n    ])\n    \n    transforms[\"tensorflow\"] = A.Compose([\n        A.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n        ToTensorV2()\n    ])\n    return transforms\n\n_TRANSFORMS = get_model_transforms()\n\n# -------------------------\n# 8. INFERENCE: MODEL LOADING\n# -------------------------\ndef load_all_models() -> Dict[str, List[nn.Module]]:\n    \"\"\"\n    Loads all 9 models (3 archs x 3 folds) from the MODEL_DIR.\n    This function automatically finds the BEST scoring model for each fold.\n    \"\"\"\n    loaded_models = {}\n    \n    print(f\"Loading models from: {config.MODEL_DIR}\")\n    \n    for prefix, backbone_name in config.MODELS_TO_TRAIN:\n        print(f\"\\n--- Loading architecture: {prefix} (Backbone: {backbone_name}) ---\")\n        \n        fold_models = []\n        for fold in range(config.NUM_FOLDS):\n            # 1. Find all models for this prefix AND fold\n            model_paths = glob.glob(os.path.join(config.MODEL_DIR, f\"{prefix}_fold{fold}*.pth\"))\n            \n            if not model_paths:\n                print(f\"FATAL: No model found for {prefix} Fold {fold}. Check dataset.\")\n                return None # Signal failure\n            \n            # 2. Find the one with the best score in its name\n            try:\n                best_path = sorted(model_paths, key=lambda x: float(x.split('score')[-1].replace('.pth', '')))[-1]\n            except Exception as e:\n                print(f\"  ERROR: Could not parse score from filenames for {prefix} Fold {fold}: {e}\")\n                print(f\"  Using first file found: {model_paths[0]}\")\n                best_path = model_paths[0]\n                \n            print(f\"  Loading best model for Fold {fold}: {os.path.basename(best_path)}\")\n            \n            # 3. Load the model\n            model = ImprovedMultiFrameModel(\n                model_name_backbone=backbone_name,\n                pretrained=False \n            )\n            \n            try:\n                ck = torch.load(best_path, map_location=device, weights_only=False)\n                model.load_state_dict(ck['model_state_dict'])\n            except Exception as e:\n                print(f\"    ERROR loading checkpoint: {e}\")\n                return None # Signal failure\n            \n            model.to(device)\n            model.eval()\n            fold_models.append(model)\n            \n        loaded_models[prefix] = fold_models\n        \n    print(f\"\\nSuccessfully loaded {sum(len(m) for m in loaded_models.values())} total models.\")\n    return loaded_models\n\n_LOADED_MODELS = load_all_models()\n\n# -------------------------\n# 9. INFERENCE FUNCTION (The \"predict\" function)\n# -------------------------\n@torch.no_grad()\ndef predict(series_path: str) -> pl.DataFrame:\n    \"\"\"\n    Main inference function called by the server.\n    Reads DICOMs, preprocesses them to match training, and runs ensemble inference.\n    \"\"\"\n    if not _LOADED_MODELS:\n         print(\"ERROR: Models are not loaded. Returning 0.5\")\n         return pl.DataFrame([tuple([0.5] * len(TARGET_COLS))], schema=TARGET_COLS)\n\n    # ------------- 1. Collect & Sample Files -------------\n    all_filepaths = sorted(glob.glob(os.path.join(series_path, \"*.dcm\")))\n    if len(all_filepaths) == 0:\n        return pl.DataFrame([tuple([0.5] * len(TARGET_COLS))], schema=TARGET_COLS)\n    \n    chosen_paths = smart_8_frame_sampling(all_filepaths)\n    \n    # ------------- 2. Preprocess DICOMs (Matching your training) -------------\n    volume = []\n    modality = 'CT'\n    for i, fp in enumerate(chosen_paths):\n        try:\n            ds = pydicom.dcmread(fp, force=True)\n            if i == 0:\n                modality = getattr(ds, 'Modality', 'CT')\n                \n            img = ds.pixel_array.astype(np.float32)\n            \n            if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):\n                img = img * float(ds.RescaleSlope) + float(ds.RescaleIntercept)\n            \n            wc, ww = get_windowing_params(modality)\n            img = apply_dicom_windowing(img, wc, ww)\n            img = apply_clahe_normalization(img, modality)\n            img = cv2.resize(img, (config.IMAGE_SIZE, config.IMAGE_SIZE), interpolation=cv2.INTER_AREA)\n            volume.append(img)\n        except Exception:\n            volume.append(np.zeros((config.IMAGE_SIZE, config.IMAGE_SIZE), dtype=np.uint8))\n\n    while len(volume) < 8:\n        volume.append(np.zeros((config.IMAGE_SIZE, config.IMAGE_SIZE), dtype=np.uint8))\n        \n    vol_np = np.array(volume)\n    \n    # ------------- 3. Create 3-Channel Input (matching training) -------------\n    vol_norm = robust_normalization(vol_np)\n    input_hwc = create_3channel_input_8frame(vol_norm)\n    \n    # ------------- 4. Get Metadata Placeholder -------------\n    meta_tensor = torch.tensor([[0.5, 0.5]], dtype=torch.float32).to(device)\n\n    # ------------- 5. Model Inference (Ensemble Average) -------------\n    all_arch_probs = [] # Store the 3 main predictions\n    \n    for prefix, fold_models in _LOADED_MODELS.items():\n        backbone_name = config.MODELS_TO_TRAIN_DICT[prefix]\n        \n        # Get correct transform\n        if 'tf_' in backbone_name:\n            transform = _TRANSFORMS[\"tensorflow\"]\n        else:\n            transform = _TRANSFORMS[\"pytorch\"]\n        \n        img_tensor = transform(image=input_hwc)['image'].unsqueeze(0).to(device)\n        \n        fold_probs_list = [] # Store the 3 fold predictions for this arch\n        \n        # Loop over this arch's 3 fold models\n        for model in fold_models:\n            with torch.cuda.amp.autocast():\n                # Standard pred\n                logits = model(img_tensor, meta_tensor)\n                probs = torch.sigmoid(logits)\n                \n                # TTA\n                if config.TTA_ENABLED:\n                    img_tensor_flipped = torch.flip(img_tensor, dims=[-1])\n                    logits_f = model(img_tensor_flipped, meta_tensor)\n                    probs_f = torch.sigmoid(logits_f)\n                    probs = (probs + probs_f) / 2.0\n            \n            fold_probs_list.append(probs)\n        \n        # Level 2: Fold Averaging\n        arch_prob = torch.mean(torch.stack(fold_probs_list, dim=0), dim=0)\n        all_arch_probs.append(arch_prob)\n    \n    # Level 3: Model Averaging\n    final_probs = torch.mean(torch.stack(all_arch_probs, dim=0), dim=0)\n    \n    # Format for polars DataFrame\n    row = final_probs.cpu().numpy()[0].tolist()\n    predictions = pl.DataFrame([tuple(row)], schema=TARGET_COLS)\n\n    return predictions\n\n# --------------------------\n# 10. START SERVER\n# --------------------------\nprint(\"Starting RSNA Inference Server...\")\n# This server will call your `predict()` function for each test series\ninference_server = rsna_inference_server.RSNAInferenceServer(predict)\ninference_server.serve()\n\n# --- Clean up memory after server is done (if it ever exits) ---\nif '_LOADED_MODELS' in locals() or '_LOADED_MODELS' in globals():\n    del _LOADED_MODELS\ngc.collect()\ntorch.cuda.empty_cache()\n\nprint(\"\\nScript finished.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T04:29:04.735651Z","iopub.execute_input":"2025-11-17T04:29:04.736341Z","iopub.status.idle":"2025-11-17T04:29:47.416236Z","shell.execute_reply.started":"2025-11-17T04:29:04.736314Z","shell.execute_reply":"2025-11-17T04:29:47.415527Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}