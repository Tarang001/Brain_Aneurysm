{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52d877be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-15T12:08:17.437650Z",
     "iopub.status.busy": "2025-11-15T12:08:17.437387Z",
     "iopub.status.idle": "2025-11-15T12:09:23.496866Z",
     "shell.execute_reply": "2025-11-15T12:09:23.496012Z"
    },
    "papermill": {
     "duration": 66.064175,
     "end_time": "2025-11-15T12:09:23.498078",
     "exception": false,
     "start_time": "2025-11-15T12:08:17.433903",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/albumentations/check_version.py:147: UserWarning: Error fetching version info <urlopen error [Errno -3] Temporary failure in name resolution>\n",
      "  data = fetch_version_info()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Found 6 checkpoints for ensemble.\n",
      "Loading checkpoint: /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch10_score0.609154.pth\n",
      "Warning: Failed to load model /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch10_score0.609154.pth. Error: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "Loading checkpoint: /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch1_score0.575996.pth\n",
      "Warning: Failed to load model /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch1_score0.575996.pth. Error: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "Loading checkpoint: /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch2_score0.576621.pth\n",
      "Warning: Failed to load model /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch2_score0.576621.pth. Error: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "Loading checkpoint: /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch3_score0.591489.pth\n",
      "Warning: Failed to load model /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch3_score0.591489.pth. Error: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "Loading checkpoint: /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch5_score0.600076.pth\n",
      "Warning: Failed to load model /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch5_score0.600076.pth. Error: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "Loading checkpoint: /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch7_score0.604576.pth\n",
      "Warning: Failed to load model /kaggle/input/effecient-net-models/eightframe_efficientnetv2s_fold0_epoch7_score0.604576.pth. Error: Weights only load failed. This file can still be loaded, to do so you have two options, \u001b[1mdo those steps only if you trust the source of the checkpoint\u001b[0m. \n",
      "\t(1) In PyTorch 2.6, we changed the default value of the `weights_only` argument in `torch.load` from `False` to `True`. Re-running `torch.load` with `weights_only` set to `False` will likely succeed, but it can result in arbitrary code execution. Do it only if you got the file from a trusted source.\n",
      "\t(2) Alternatively, to load with `weights_only=True` please check the recommended steps in the following error message.\n",
      "\tWeightsUnpickler error: Unsupported global: GLOBAL numpy.core.multiarray.scalar was not an allowed global by default. Please use `torch.serialization.add_safe_globals([scalar])` or the `torch.serialization.safe_globals([scalar])` context manager to allowlist this global if you trust this class/function.\n",
      "\n",
      "Check the documentation of torch.load to learn more about types accepted by default with weights_only https://pytorch.org/docs/stable/generated/torch.load.html.\n",
      "Successfully loaded 0 models.\n",
      "Starting RSNA Inference Server...\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# PHASE 2: SUBMISSION NOTEBOOK (Internet OFF)\n",
    "# ==========================================\n",
    "\n",
    "# -------------------------\n",
    "# 1. GLOBAL IMPORTS\n",
    "# -------------------------\n",
    "# All these libraries are pre-installed in the Kaggle environment.\n",
    "# No !pip install is needed.\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import functools\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from typing import List, Tuple, Optional\n",
    "import gc\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import timm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import pydicom\n",
    "import polars as pl\n",
    "\n",
    "# This is the competition's inference server\n",
    "import kaggle_evaluation.rsna_inference_server as rsna_inference_server\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# -------------------------\n",
    "# 2. GLOBAL CONFIGURATION\n",
    "# -------------------------\n",
    "class Config:\n",
    "    # --- This path is from your screenshot ---\n",
    "    CKPT_DIR = \"/kaggle/input/effecient-net-models\" \n",
    "    \n",
    "    # --- Model Hyperparameters (must match training) ---\n",
    "    NUM_FRAMES = 8\n",
    "    IMAGE_SIZE = 224\n",
    "    NUM_CLASSES = 14\n",
    "    MODEL_NAME_BACKBONE = \"tf_efficientnetv2_s.in1k\"\n",
    "    \n",
    "    # --- Feature Flags (must match training) ---\n",
    "    USE_METADATA = True\n",
    "    USE_WINDOWING = True\n",
    "    USE_CLAHE = True\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# -------------------------\n",
    "# 3. GLOBAL SEED & DEVICE\n",
    "# -------------------------\n",
    "def set_seed(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "set_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# -------------------------\n",
    "# 4. GLOBAL TARGETS\n",
    "# -------------------------\n",
    "TARGET_COLS = [\n",
    "    'Left Infraclinoid Internal Carotid Artery', 'Right Infraclinoid Internal Carotid Artery', \n",
    "    'Left Supraclinoid Internal Carotid Artery', 'Right Supraclinoid Internal Carotid Artery',\n",
    "    'Left Middle Cerebral Artery', 'Right Middle Cerebral Artery',\n",
    "    'Anterior Communicating Artery', 'Left Anterior Cerebral Artery',\n",
    "    'Right Anterior Cerebral Artery', 'Left Posterior Communicating Artery',\n",
    "    'Right Posterior Communicating Artery', 'Basilar Tip',\n",
    "    'Other Posterior Circulation', 'Aneurysm Present'\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# 5. PREPROCESSING (Must match training)\n",
    "# -------------------------\n",
    "# These functions are identical to your training notebook\n",
    "def get_windowing_params(modality: str) -> Tuple[float, float]:\n",
    "    windows = {'CT': (40, 80), 'CTA': (50, 350), 'MRA': (600, 1200), 'MRI': (40, 80), 'MR': (40, 80)}\n",
    "    return windows.get(modality, (40, 80))\n",
    "\n",
    "def apply_dicom_windowing(img: np.ndarray, window_center: float, window_width: float) -> np.ndarray:\n",
    "    img_min = window_center - window_width // 2\n",
    "    img_max = window_center + window_width // 2\n",
    "    img = np.clip(img, img_min, img_max)\n",
    "    img = (img - img_min) / (img_max - img_min + 1e-7)\n",
    "    return (img * 255).astype(np.uint8)\n",
    "\n",
    "def apply_clahe_normalization(img: np.ndarray, modality: str) -> np.ndarray:\n",
    "    if not config.USE_CLAHE: return img.astype(np.uint8)\n",
    "    img = img.astype(np.uint8)\n",
    "    if modality in ['CTA', 'MRA']:\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        img_clahe = clahe.apply(img)\n",
    "        img_clahe = cv2.convertScaleAbs(img_clahe, alpha=1.1, beta=5)\n",
    "    elif modality in ['MRI', 'MR']:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "        img_clahe = clahe.apply(img)\n",
    "        img_clahe = np.power(img_clahe / 255.0, 0.9) * 255\n",
    "        img_clahe = img_clahe.astype(np.uint8)\n",
    "    else:\n",
    "        clahe = cv2.createCLAHE(clipLimit=2.5, tileGridSize=(8, 8))\n",
    "        img_clahe = clahe.apply(img)\n",
    "    return img_clahe\n",
    "\n",
    "def robust_normalization(volume: np.ndarray) -> np.ndarray:\n",
    "    p1, p99 = np.percentile(volume.flatten(), [1, 99])\n",
    "    volume_norm = np.clip(volume, p1, p99)\n",
    "    if p99 > p1:\n",
    "        volume_norm = (volume_norm - p1) / (p99 - p1 + 1e-7)\n",
    "    else:\n",
    "        volume_norm = np.zeros_like(volume_norm)\n",
    "    return (volume_norm * 255).astype(np.uint8)\n",
    "\n",
    "def create_3channel_input_8frame(volume: np.ndarray) -> np.ndarray:\n",
    "    if len(volume) == 0:\n",
    "        return np.zeros((config.IMAGE_SIZE, config.IMAGE_SIZE, 3), dtype=np.uint8)\n",
    "    middle_slice = volume[len(volume) // 2]\n",
    "    mip = np.max(volume, axis=0)\n",
    "    std_proj = np.std(volume, axis=0).astype(np.float32)\n",
    "    if std_proj.max() > std_proj.min():\n",
    "        p1, p99 = np.percentile(std_proj, [5, 95])\n",
    "        std_proj = np.clip(std_proj, p1, p99)\n",
    "        std_proj = ((std_proj - p1) / (p99 - p1 + 1e-7) * 255).astype(np.uint8)\n",
    "    else:\n",
    "        std_proj = np.zeros_like(std_proj, dtype=np.uint8)\n",
    "    return np.stack([middle_slice, mip, std_proj], axis=-1)\n",
    "\n",
    "# This is the Albumentations transform that matches your validation transform\n",
    "val_transform = A.Compose([\n",
    "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# 6. MODEL DEFINITION (Must match training)\n",
    "# -------------------------\n",
    "class ImprovedMultiFrameModel(nn.Module):\n",
    "    def __init__(self, num_frames=8, num_classes=14, pretrained=False):\n",
    "        super(ImprovedMultiFrameModel, self).__init__()\n",
    "        self.num_frames = num_frames\n",
    "        self.num_classes = num_classes\n",
    "        self.use_metadata = config.USE_METADATA\n",
    "        \n",
    "        # NOTE: pretrained=False because Internet is OFF\n",
    "        self.backbone = timm.create_model(\n",
    "            config.MODEL_NAME_BACKBONE,\n",
    "            pretrained=pretrained,\n",
    "            num_classes=0,\n",
    "            global_pool='avg'\n",
    "        )\n",
    "        self.feature_dim = self.backbone.num_features\n",
    "        \n",
    "        if self.use_metadata:\n",
    "            self.meta_fc = nn.Sequential(\n",
    "                nn.Linear(2, 16), nn.ReLU(), nn.Dropout(0.2),\n",
    "                nn.Linear(16, 32), nn.ReLU()\n",
    "            )\n",
    "            classifier_input_dim = self.feature_dim + 32\n",
    "        else:\n",
    "            classifier_input_dim = self.feature_dim\n",
    "            \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(classifier_input_dim, 512),\n",
    "            nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, meta=None):\n",
    "        features = self.backbone(x)\n",
    "        if self.use_metadata and meta is not None:\n",
    "            meta_features = self.meta_fc(meta)\n",
    "            features = torch.cat([features, meta_features], dim=1)\n",
    "        output = self.classifier(features)\n",
    "        return output\n",
    "\n",
    "# --------------------------\n",
    "# 7. LOAD ENSEMBLE MODELS\n",
    "# --------------------------\n",
    "def discover_ckpts(ckpt_dir):\n",
    "    files = sorted(glob.glob(os.path.join(ckpt_dir, \"*.pth\")) + glob.glob(os.path.join(ckpt_dir, \"*.pt\")))\n",
    "    return files\n",
    "\n",
    "CKPT_PATHS = discover_ckpts(config.CKPT_DIR)\n",
    "_LOADED_MODELS = []\n",
    "\n",
    "if len(CKPT_PATHS) == 0:\n",
    "    print(f\"ERROR: No .pth files found in {config.CKPT_DIR}. Did you update the path?\")\n",
    "else:\n",
    "    print(f\"Found {len(CKPT_PATHS)} checkpoints for ensemble.\")\n",
    "    for p in CKPT_PATHS:\n",
    "        print(f\"Loading checkpoint: {p}\")\n",
    "        model = ImprovedMultiFrameModel(num_frames=config.NUM_FRAMES, num_classes=config.NUM_CLASSES, pretrained=False)\n",
    "        try:\n",
    "            ck = torch.load(p, map_location=device)\n",
    "            \n",
    "            if isinstance(ck, dict) and 'model_state_dict' in ck:\n",
    "                state = ck['model_state_dict']\n",
    "            else:\n",
    "                state = ck\n",
    "            \n",
    "            sd = {}\n",
    "            for k, v in state.items():\n",
    "                nk = k[len('module.'):] if k.startswith('module.') else k\n",
    "                sd[nk] = v\n",
    "            \n",
    "            model.load_state_dict(sd, strict=True)\n",
    "            model.to(device)\n",
    "            model.eval()\n",
    "            _LOADED_MODELS.append(model)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Failed to load model {p}. Error: {e}\")\n",
    "\n",
    "print(f\"Successfully loaded {len(_LOADED_MODELS)} models.\")\n",
    "\n",
    "# --------------------------\n",
    "# 8. INFERENCE FUNCTION\n",
    "# --------------------------\n",
    "def sample_eight_from_list(paths: List[str]) -> List[str]:\n",
    "    n = len(paths)\n",
    "    if n == 0: return []\n",
    "    if n <= 8:\n",
    "        out = paths[:]\n",
    "        while len(out) < 8:\n",
    "            out += paths[:(8 - len(out))]\n",
    "        return out[:8]\n",
    "    idxs = np.linspace(0, n - 1, 8).astype(int).tolist()\n",
    "    return [paths[i] for i in idxs]\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict(series_path: str) -> pl.DataFrame:\n",
    "    \"\"\"\n",
    "    Main inference function called by the server.\n",
    "    Reads DICOMs, preprocesses them to match training, and runs ensemble inference.\n",
    "    \"\"\"\n",
    "    # ------------- 1. Collect files -------------\n",
    "    all_filepaths = sorted(glob.glob(os.path.join(series_path, \"*.dcm\")))\n",
    "    \n",
    "    if len(all_filepaths) == 0:\n",
    "        return pl.DataFrame([tuple([0.5] * len(TARGET_COLS))], schema=TARGET_COLS)\n",
    "\n",
    "    # ------------- 2. Sample 8 frames -------------\n",
    "    chosen_paths = sample_eight_from_list(all_filepaths)\n",
    "    \n",
    "    # ------------- 3. Preprocess DICOMs (Matching your training) -------------\n",
    "    volume = []\n",
    "    modality = 'CT'\n",
    "    \n",
    "    for i, fp in enumerate(chosen_paths):\n",
    "        try:\n",
    "            ds = pydicom.dcmread(fp, force=True)\n",
    "            if i == 0:\n",
    "                modality = getattr(ds, 'Modality', 'CT')\n",
    "                \n",
    "            img = ds.pixel_array.astype(np.float32)\n",
    "            \n",
    "            if hasattr(ds, 'RescaleSlope') and hasattr(ds, 'RescaleIntercept'):\n",
    "                img = img * float(ds.RescaleSlope) + float(ds.RescaleIntercept)\n",
    "            \n",
    "            wc, ww = get_windowing_params(modality)\n",
    "            img = apply_dicom_windowing(img, wc, ww)\n",
    "            img = apply_clahe_normalization(img, modality)\n",
    "            \n",
    "            img = cv2.resize(img, (config.IMAGE_SIZE, config.IMAGE_SIZE), interpolation=cv2.INTER_AREA)\n",
    "            volume.append(img)\n",
    "        except Exception:\n",
    "            volume.append(np.zeros((config.IMAGE_SIZE, config.IMAGE_SIZE), dtype=np.uint8))\n",
    "\n",
    "    while len(volume) < 8:\n",
    "        volume.append(np.zeros((config.IMAGE_SIZE, config.IMAGE_SIZE), dtype=np.uint8))\n",
    "        \n",
    "    vol_np = np.array(volume)\n",
    "    \n",
    "    # ------------- 4. Create 3-Channel Input (matching training) -------------\n",
    "    vol_norm = robust_normalization(vol_np)\n",
    "    input_hwc = create_3channel_input_8frame(vol_norm)\n",
    "    \n",
    "    # ------------- 5. Convert to Tensor (matching training) -------------\n",
    "    # Apply the same validation transform\n",
    "    # val_transform handles Normalize and ToTensorV2 (permute + scaling)\n",
    "    img_normalized = val_transform(image=input_hwc)['image'] \n",
    "    img_tensor = img_normalized.unsqueeze(0).to(device)\n",
    "    \n",
    "    # Metadata placeholder (real metadata is unavailable in test set)\n",
    "    meta_tensor = torch.tensor([[0.5, 0.5]], dtype=torch.float32).to(device)\n",
    "\n",
    "    # ------------- 6. Model Inference (Ensemble Average) -------------\n",
    "    preds_accum = None\n",
    "    \n",
    "    if not _LOADED_MODELS: # Safety check\n",
    "         return pl.DataFrame([tuple([0.5] * len(TARGET_COLS))], schema=TARGET_COLS)\n",
    "\n",
    "    for model in _LOADED_MODELS:\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Standard pred\n",
    "            logits = model(img_tensor, meta_tensor)\n",
    "            probs = torch.sigmoid(logits)\n",
    "            \n",
    "            # TTA (Horizontal Flip)\n",
    "            flipped = torch.flip(img_tensor, dims=[-1])\n",
    "            logits_f = model(flipped, meta_tensor)\n",
    "            probs_f = torch.sigmoid(logits_f)\n",
    "        \n",
    "        # Average TTA\n",
    "        probs = (probs + probs_f) / 2.0\n",
    "        \n",
    "        preds_accum = probs if preds_accum is None else preds_accum + probs\n",
    "\n",
    "    # Average ensemble predictions\n",
    "    preds_accum = (preds_accum / len(_LOADED_MODELS)).cpu().numpy()\n",
    "\n",
    "    row = preds_accum[0].tolist()\n",
    "    predictions = pl.DataFrame([tuple(row)], schema=TARGET_COLS)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# --------------------------\n",
    "# 9. START SERVER\n",
    "# --------------------------\n",
    "print(\"Starting RSNA Inference Server...\")\n",
    "# This server will call your `predict()` function for each test series\n",
    "inference_server = rsna_inference_server.RSNAInferenceServer(predict)\n",
    "inference_server.serve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c22865",
   "metadata": {
    "papermill": {
     "duration": 0.001846,
     "end_time": "2025-11-15T12:09:23.502362",
     "exception": false,
     "start_time": "2025-11-15T12:09:23.500516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66715b68",
   "metadata": {
    "papermill": {
     "duration": 0.001836,
     "end_time": "2025-11-15T12:09:23.506173",
     "exception": false,
     "start_time": "2025-11-15T12:09:23.504337",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bbcedd",
   "metadata": {
    "papermill": {
     "duration": 0.00187,
     "end_time": "2025-11-15T12:09:23.509863",
     "exception": false,
     "start_time": "2025-11-15T12:09:23.507993",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8926a0",
   "metadata": {
    "papermill": {
     "duration": 0.001855,
     "end_time": "2025-11-15T12:09:23.513742",
     "exception": false,
     "start_time": "2025-11-15T12:09:23.511887",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02426715",
   "metadata": {
    "papermill": {
     "duration": 0.001733,
     "end_time": "2025-11-15T12:09:23.517253",
     "exception": false,
     "start_time": "2025-11-15T12:09:23.515520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 13851420,
     "isSourceIdPinned": false,
     "sourceId": 99552,
     "sourceType": "competition"
    },
    {
     "datasetId": 8739150,
     "sourceId": 13735059,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8744136,
     "sourceId": 13742486,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 71.929037,
   "end_time": "2025-11-15T12:09:25.440438",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-15T12:08:13.511401",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
